{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal adversarial training\n",
    "\n",
    "An implementation of the universal adversarial training as proposed in [Universal adversarial training](https://arxiv.org/pdf/1811.11304.pdf) by Shafahi et al. \n",
    "\n",
    "Author(s): [Martin Benning](mailto:m.benning@qmul.ac.uk), [Alex Wendland](mailto:a.p.wendland@gmail.com)\n",
    "\n",
    "Date: 15.05.2019\n",
    "\n",
    "Last modified: 15.05.2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem description\n",
    "\n",
    "In the following code we want to train image identifiers to defend against pertubation attacks, such as FGSM and universal adversarial attacks. Then test their proformances against such attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages.\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a neural network architecture\n",
    "\n",
    "There are two types of networks here:\n",
    "\n",
    " - Image classifier, and\n",
    " - Pertubation generator.\n",
    " \n",
    "Net (Image Classifier)\n",
    "\n",
    "Input: 28 x 28 byte black and white image (1 channel).\n",
    "Output: 10 dimensional probability vector.\n",
    "\n",
    "Layers:\n",
    "    \n",
    "Convolusion layer 5x5 grid outputting 10 channels,\n",
    "\n",
    "Convolusion layer 5x5 grid outputting 20 channels,\n",
    "\n",
    "Rectified linear unit layer 320 to 50, and\n",
    "\n",
    "Soft max linear layer 50 to 10.\n",
    "\n",
    "Net_Attack (Pertubation generator)\n",
    "\n",
    "Input: 28 x 28 byte black and white image (1 channel).\n",
    "Output: 28 x 28 byte pertubation (max value = epsilon).\n",
    "\n",
    "Layers:\n",
    "    \n",
    "Rectified linear unit layer 784 to 784,\n",
    "\n",
    "Rectified linear unit layer 784 to 784,\n",
    "\n",
    "Linear layer 784 to 784, and\n",
    "\n",
    "Clamps values between 0 and epsilon (= 3 unless specified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet Model definition\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "# Attacking Model definition\n",
    "    \n",
    "class Net_Attack(nn.Module):\n",
    "    def __init__(self,epsilon = 3):\n",
    "        super(Net_Attack, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 28*28)\n",
    "        self.fc2 = nn.Linear(28*28, 28*28)\n",
    "        self.fc3 = nn.Linear(28*28, 28*28)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.clamp(x,0,self.epsilon)\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MINST Data Set\n",
    "\n",
    "For the tests we used the [MINST](https://www.nist.gov/node/1298471/emnist-dataset) data set.\n",
    "\n",
    "The following loads the data set into a trainer and test loader.\n",
    "\n",
    "The user can change the batch_size of the train_loader to effect how many updates there are in one epoch. However changing the batch_size of the test_loader will break the testing code, it requires to be set to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Test dataset and dataloader declaration\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])), \n",
    "        batch_size=600, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            ])), \n",
    "        batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation models\n",
    "\n",
    "Use the following code to load the models we used to generate the test data presented in the report, for this we took the following variables:\n",
    "\n",
    "stepsize     - 0.05\n",
    "\n",
    "epsilon      - 3\n",
    "\n",
    "cap          - 1\n",
    "\n",
    "mom          - 0.8\n",
    "\n",
    "no_of_epochs - 200\n",
    "\n",
    "These were choosen after some experimentation, with no scientific reasoning.\n",
    "\n",
    "If you wish to generate your own model skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to load saved networks for the tests ran within the documentation.\n",
    "# User can edit this to upload their trained models.\n",
    "\n",
    "model_vani = Net()\n",
    "model_vani.load_state_dict(torch.load('..\\data\\model\\doc_model_vani_200'))\n",
    "\n",
    "model_pert = Net()\n",
    "model_pert.load_state_dict(torch.load('..\\data\\model\\doc_model_pert_200'))\n",
    "\n",
    "model_def = Net()\n",
    "model_def.load_state_dict(torch.load('..\\data\\model\\doc_model_def_200'))\n",
    "\n",
    "model_atk = Net_Attack()\n",
    "model_atk.load_state_dict(torch.load('..\\data\\model\\doc_model_atk_200'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training new models\n",
    "\n",
    "The following code will train new models, if you have loaded the models above skip these steps and progress to the testing block.\n",
    "\n",
    "These models have the following variables.\n",
    "\n",
    "stepsize     - The learning rate, how far in the direction of the steepist decent we move.\n",
    "\n",
    "epsilon      - How much the attackers are allowed to peterbe the image.\n",
    "\n",
    "cap          - The cap for the loss function, see the paper for clarification.\n",
    "\n",
    "mom          - The momentum within the learning, how much it gets effected by the new change in direction.\n",
    "\n",
    "no_of_epochs - The number times you run through all the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables for training the models.\n",
    "\n",
    "stepsize = 0.05\n",
    "epsilon = 3\n",
    "cap = 1\n",
    "mom = 0.8\n",
    "no_of_epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the capped Mean Squared Error loss function, as defined in the paper.\n",
    "\n",
    "# Input:  The output of a test of the model, the correct answers to the test and the value to cap each individual test error at.\n",
    "# Output: The average of the capped errors of the test.\n",
    "\n",
    "def mse_loss_cap(output, target, cap = 1):\n",
    "    \n",
    "    # define the one hot matrix with the answer values being -1\n",
    "    \n",
    "    one_hot = torch.zeros(output.size(0),output.size(1))\n",
    "    for i in range(output.size(0)):\n",
    "        one_hot[i][int(target[i].item())] = -1\n",
    "    \n",
    "    # add output of the model and calculate loss function\n",
    "    \n",
    "    loss = torch.add(output, one_hot)\n",
    "    loss = torch.pow(loss, 2)\n",
    "    loss = torch.sum(loss, 1)\n",
    "    loss = torch.clamp(loss,0,cap)\n",
    "    \n",
    "    return torch.mean(loss)\n",
    "\n",
    "# Input:  The output of a test of the model, the correct answers to the test and the value to cap each individual test error at.\n",
    "# Output: The average of the error values from the test.\n",
    "\n",
    "def mse_loss_atk(data, target, cap = 1):\n",
    "    \n",
    "    # define the one hot matrix with the answer values being -1\n",
    "    \n",
    "    one_hot = torch.zeros(output.size(0),output.size(1))\n",
    "    for i in range(output.size(0)):\n",
    "        one_hot[i][int(target[i].item())] = -1\n",
    "    \n",
    "    # add output of the model and calculate loss function\n",
    "    \n",
    "    loss = torch.add(output, one_hot)\n",
    "    loss = torch.pow(loss, 2)\n",
    "    loss = torch.sum(loss, 1)\n",
    "    loss = torch.clamp(loss,0,cap)\n",
    "    \n",
    "    # Take one minus values, to turn into minimisation problem.\n",
    "    \n",
    "    loss = torch.mul(loss,-1)\n",
    "    loss = torch.add(torch.ones(loss.size(0)), loss)\n",
    "    \n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [5/200], Loss: 0.1526\n",
      "Iteration [10/200], Loss: 0.1174\n",
      "Iteration [15/200], Loss: 0.0843\n",
      "Iteration [20/200], Loss: 0.0878\n",
      "Iteration [25/200], Loss: 0.0786\n",
      "Iteration [30/200], Loss: 0.0641\n",
      "Iteration [35/200], Loss: 0.0816\n",
      "Iteration [40/200], Loss: 0.0743\n",
      "Iteration [45/200], Loss: 0.0662\n",
      "Iteration [50/200], Loss: 0.0446\n",
      "Iteration [55/200], Loss: 0.0752\n",
      "Iteration [60/200], Loss: 0.0457\n",
      "Iteration [65/200], Loss: 0.0607\n",
      "Iteration [70/200], Loss: 0.0443\n",
      "Iteration [75/200], Loss: 0.0625\n",
      "Iteration [80/200], Loss: 0.0524\n",
      "Iteration [85/200], Loss: 0.0539\n",
      "Iteration [90/200], Loss: 0.0581\n",
      "Iteration [95/200], Loss: 0.0653\n",
      "Iteration [100/200], Loss: 0.0517\n",
      "Iteration [105/200], Loss: 0.0399\n",
      "Iteration [110/200], Loss: 0.0603\n",
      "Iteration [115/200], Loss: 0.0429\n",
      "Iteration [120/200], Loss: 0.0630\n",
      "Iteration [125/200], Loss: 0.0553\n",
      "Iteration [130/200], Loss: 0.0538\n",
      "Iteration [135/200], Loss: 0.0651\n",
      "Iteration [140/200], Loss: 0.0264\n",
      "Iteration [145/200], Loss: 0.0324\n",
      "Iteration [150/200], Loss: 0.0531\n",
      "Iteration [155/200], Loss: 0.0462\n",
      "Iteration [160/200], Loss: 0.0551\n",
      "Iteration [165/200], Loss: 0.0527\n",
      "Iteration [170/200], Loss: 0.0617\n",
      "Iteration [175/200], Loss: 0.0549\n",
      "Iteration [180/200], Loss: 0.0456\n",
      "Iteration [185/200], Loss: 0.0442\n",
      "Iteration [190/200], Loss: 0.0364\n",
      "Iteration [195/200], Loss: 0.0398\n",
      "Iteration [200/200], Loss: 0.0203\n"
     ]
    }
   ],
   "source": [
    "# Trains a vanila model with no defence against pertubation attacks.\n",
    "\n",
    "# Initialse the net and the optimiser.\n",
    "\n",
    "model_vani = Net()\n",
    "optimiser = optim.SGD(model_vani.parameters(), lr=stepsize, momentum=mom)\n",
    "\n",
    "# Trains the model for the given number of epochs.\n",
    "\n",
    "for epoch in range(no_of_epochs):\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        \n",
    "        # Runs the model.\n",
    "        \n",
    "        output = model_vani(data)\n",
    "        \n",
    "        # Calculates the loss function.\n",
    "        \n",
    "        loss = mse_loss_cap(output, target,cap)\n",
    "        \n",
    "        # Gradient descent for weights.\n",
    "        \n",
    "        model_vani.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    \n",
    "    # Informs the user the iteration number every 5 steps.\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print ('Iteration [%d/%d], Loss: %.4f' \n",
    "                %(epoch + 1, no_of_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [5/200], Loss: 0.2671\n",
      "Iteration [10/200], Loss: 0.2068\n",
      "Iteration [15/200], Loss: 0.1875\n",
      "Iteration [20/200], Loss: 0.1724\n",
      "Iteration [25/200], Loss: 0.1580\n",
      "Iteration [30/200], Loss: 0.1422\n",
      "Iteration [35/200], Loss: 0.1435\n",
      "Iteration [40/200], Loss: 0.1731\n",
      "Iteration [45/200], Loss: 0.1536\n",
      "Iteration [50/200], Loss: 0.1419\n",
      "Iteration [55/200], Loss: 0.1319\n",
      "Iteration [60/200], Loss: 0.1353\n",
      "Iteration [65/200], Loss: 0.1344\n",
      "Iteration [70/200], Loss: 0.1561\n",
      "Iteration [75/200], Loss: 0.1187\n",
      "Iteration [80/200], Loss: 0.1289\n",
      "Iteration [85/200], Loss: 0.1493\n",
      "Iteration [90/200], Loss: 0.1327\n",
      "Iteration [95/200], Loss: 0.1474\n",
      "Iteration [100/200], Loss: 0.1598\n",
      "Iteration [105/200], Loss: 0.1276\n",
      "Iteration [110/200], Loss: 0.1327\n",
      "Iteration [115/200], Loss: 0.1574\n",
      "Iteration [120/200], Loss: 0.1299\n",
      "Iteration [125/200], Loss: 0.1115\n",
      "Iteration [130/200], Loss: 0.1315\n",
      "Iteration [135/200], Loss: 0.1318\n",
      "Iteration [140/200], Loss: 0.1417\n",
      "Iteration [145/200], Loss: 0.1338\n",
      "Iteration [150/200], Loss: 0.1142\n",
      "Iteration [155/200], Loss: 0.1302\n",
      "Iteration [160/200], Loss: 0.1291\n",
      "Iteration [165/200], Loss: 0.1025\n",
      "Iteration [170/200], Loss: 0.1279\n",
      "Iteration [175/200], Loss: 0.1205\n",
      "Iteration [180/200], Loss: 0.1063\n",
      "Iteration [185/200], Loss: 0.1326\n",
      "Iteration [190/200], Loss: 0.1118\n",
      "Iteration [195/200], Loss: 0.1214\n",
      "Iteration [200/200], Loss: 0.1483\n"
     ]
    }
   ],
   "source": [
    "# Trains a model trained against a universal adversarial attack.\n",
    "\n",
    "# Initialse the net, universal pertubation, and the optimiser.\n",
    "\n",
    "model_pert = Net()\n",
    "pertubation = Variable(torch.zeros(train_loader.dataset.data.size(1), \\\n",
    "                          train_loader.dataset.data.size(2)), requires_grad=True)\n",
    "optimiser = optim.SGD(model_pert.parameters(), lr=stepsize, momentum=mom)\n",
    "\n",
    "# Trains the model and pertubation for the given number of epochs.\n",
    "\n",
    "for epoch in range(no_of_epochs):\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        \n",
    "        # Runs the model on the data and the perturbed data.\n",
    "        \n",
    "        output_1 = model_pert(data + pertubation.repeat(train_loader.batch_size, 1, 1, 1))\n",
    "        output_2 = model_pert(data)\n",
    "        \n",
    "        # Calculates the loss function on these runs and takes the average.\n",
    "        # User can change the weighting of the loss function (eg: 7:3 split).\n",
    "        \n",
    "        loss_1 = mse_loss_cap(output_1, target, cap)\n",
    "        loss_2 = mse_loss_cap(output_2, target, cap)\n",
    "        loss = loss_1 * 0.5 + loss_2 * 0.5\n",
    "        \n",
    "        # Gradient descent for weights.\n",
    "        \n",
    "        model_pert.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        # Updates the universal pertubation with a step in the steepest decent and renormalises.\n",
    "        \n",
    "        pertubation.data = pertubation.data + stepsize * pertubation.grad\n",
    "        pertubation.data = pertubation.data / torch.norm(pertubation.data.view(-1, 784)) * epsilon\n",
    "    \n",
    "    # Informs the user the iteration number every 5 steps.\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print ('Iteration [%d/%d], Loss: %.4f' \n",
    "                %(epoch + 1, no_of_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration [5/200], Def Loss: 0.5504, Atk Loss: 0.2231\n",
      "Iteration [10/200], Def Loss: 0.5421, Atk Loss: 0.1844\n",
      "Iteration [15/200], Def Loss: 0.5160, Atk Loss: 0.1862\n",
      "Iteration [20/200], Def Loss: 0.5272, Atk Loss: 0.1841\n",
      "Iteration [25/200], Def Loss: 0.4441, Atk Loss: 0.2755\n",
      "Iteration [30/200], Def Loss: 0.4796, Atk Loss: 0.2795\n",
      "Iteration [35/200], Def Loss: 0.3109, Atk Loss: 0.5905\n",
      "Iteration [40/200], Def Loss: 0.2769, Atk Loss: 0.5898\n",
      "Iteration [45/200], Def Loss: 0.2883, Atk Loss: 0.6067\n",
      "Iteration [50/200], Def Loss: 0.3295, Atk Loss: 0.5579\n",
      "Iteration [55/200], Def Loss: 0.4419, Atk Loss: 0.3912\n",
      "Iteration [60/200], Def Loss: 0.4223, Atk Loss: 0.3935\n",
      "Iteration [65/200], Def Loss: 0.4654, Atk Loss: 0.2671\n",
      "Iteration [70/200], Def Loss: 0.4494, Atk Loss: 0.2977\n",
      "Iteration [75/200], Def Loss: 0.4546, Atk Loss: 0.2855\n",
      "Iteration [80/200], Def Loss: 0.4883, Atk Loss: 0.2434\n",
      "Iteration [85/200], Def Loss: 0.5014, Atk Loss: 0.1456\n",
      "Iteration [90/200], Def Loss: 0.4762, Atk Loss: 0.2271\n",
      "Iteration [95/200], Def Loss: 0.4455, Atk Loss: 0.2669\n",
      "Iteration [100/200], Def Loss: 0.4103, Atk Loss: 0.3669\n",
      "Iteration [105/200], Def Loss: 0.4379, Atk Loss: 0.2888\n",
      "Iteration [110/200], Def Loss: 0.4712, Atk Loss: 0.2444\n",
      "Iteration [115/200], Def Loss: 0.4626, Atk Loss: 0.2040\n",
      "Iteration [120/200], Def Loss: 0.4508, Atk Loss: 0.2213\n",
      "Iteration [125/200], Def Loss: 0.4382, Atk Loss: 0.3009\n",
      "Iteration [130/200], Def Loss: 0.4514, Atk Loss: 0.2675\n",
      "Iteration [135/200], Def Loss: 0.4572, Atk Loss: 0.2662\n",
      "Iteration [140/200], Def Loss: 0.4703, Atk Loss: 0.2358\n",
      "Iteration [145/200], Def Loss: 0.4469, Atk Loss: 0.2731\n",
      "Iteration [150/200], Def Loss: 0.4431, Atk Loss: 0.2680\n",
      "Iteration [155/200], Def Loss: 0.4931, Atk Loss: 0.1902\n",
      "Iteration [160/200], Def Loss: 0.4540, Atk Loss: 0.2332\n",
      "Iteration [165/200], Def Loss: 0.4362, Atk Loss: 0.2805\n",
      "Iteration [170/200], Def Loss: 0.4301, Atk Loss: 0.3337\n",
      "Iteration [175/200], Def Loss: 0.4614, Atk Loss: 0.2706\n",
      "Iteration [180/200], Def Loss: 0.4665, Atk Loss: 0.1893\n",
      "Iteration [185/200], Def Loss: 0.4628, Atk Loss: 0.2300\n",
      "Iteration [190/200], Def Loss: 0.4421, Atk Loss: 0.3074\n",
      "Iteration [195/200], Def Loss: 0.4313, Atk Loss: 0.3022\n",
      "Iteration [200/200], Def Loss: 0.4516, Atk Loss: 0.2848\n"
     ]
    }
   ],
   "source": [
    "# Trains an image classifying and image obsuring net simulataniously.\n",
    "\n",
    "# Initialse both nets and optimisers.\n",
    "\n",
    "model_def = Net()\n",
    "model_atk = Net_Attack(epsilon)\n",
    "optimiser_def = optim.SGD(model_def.parameters(), lr=stepsize, momentum=mom)\n",
    "optimiser_atk = optim.SGD(model_atk.parameters(), lr=stepsize, momentum=mom)\n",
    "\n",
    "# Trains both models for the given number of epochs.\n",
    "\n",
    "for epoch in range(no_of_epochs):\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        \n",
    "        # Runs the defending model on the data and the attacked data.\n",
    "        \n",
    "        output_1 = model_def(data + model_atk(data))\n",
    "        output_2 = model_def(data)\n",
    "        \n",
    "        # Calculates the loss function for the defender on these runs and takes the average.\n",
    "        # User can change the weighting of the loss function (eg: 7:3 split).\n",
    "        \n",
    "        loss_1 = mse_loss_cap(output_1, target, cap)\n",
    "        loss_2 = mse_loss_cap(output_2, target, cap)\n",
    "        loss = loss_1 * 0.5 + loss_2 * 0.5 \n",
    "        \n",
    "        # Gradient descent for defenders weights.\n",
    "        \n",
    "        def_loss = loss.item()\n",
    "        model_def.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser_def.step()\n",
    "        \n",
    "        # Runs defending model on attacked data.\n",
    "        \n",
    "        output = model_def(data + model_atk(data))\n",
    "        \n",
    "        # Calculates the loss function for the attacker.\n",
    "        \n",
    "        loss = mse_loss_atk(output, target)\n",
    "        \n",
    "        # Gradient descent for defenders weights.\n",
    "        \n",
    "        model_atk.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser_atk.step()\n",
    "    \n",
    "    # Informs the user the iteration number every 5 steps.\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print ('Iteration [%d/%d], Def Loss: %.4f, Atk Loss: %.4f' \n",
    "                %(epoch + 1, no_of_epochs, def_loss, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will save your trained models.\n",
    "\n",
    "torch.save(model_vani.state_dict(), '..\\data\\model\\user_model_vani_{}'.format(no_of_epochs))\n",
    "torch.save(model_pert.state_dict(), '..\\data\\model\\user_model_pert_{}'.format(no_of_epochs))\n",
    "torch.save(model_def.state_dict(), '..\\data\\model\\user_model_def_{}'.format(no_of_epochs))\n",
    "torch.save(model_atk.state_dict(), '..\\data\\model\\user_model_atk_{}'.format(no_of_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing models\n",
    "\n",
    "The following code will test the models against two types of attacks:\n",
    "\n",
    " - FGSM attacks, and\n",
    " - Universal adversarial attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These functions are used to proform the FGSM attack tests.\n",
    "\n",
    "# Generates the FGSM attack.\n",
    "# Input: An image to attack, maximum pertubation amount and gradient perturb the image.\n",
    "# Ouput: A perturbed image.\n",
    "\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    \n",
    "    # Collect the element-wise sign of the data gradient.\n",
    "    \n",
    "    sign_data_grad = data_grad.sign()\n",
    "    \n",
    "    # Create the perturbed image by adjusting each pixel of the input image.\n",
    "    \n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    \n",
    "    # Adding clipping to maintain [0,1] range.\n",
    "    \n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    \n",
    "    # Return the perturbed image.\n",
    "    \n",
    "    return perturbed_image\n",
    "\n",
    "# Runs a batch of tests for the FGSM attack. \n",
    "# Input: The model you want to test, the test data, and the maximum pertubation amount.\n",
    "# Ouput: The accuracy of the model against this FGSM attack and examples of pertubations that broke it.\n",
    "\n",
    "def test(model, epsilon, test_loader = test_loader):\n",
    "    \n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        \n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Runs the model.\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        # Finds initial prediction, if this is already wrong we don't bother attacking.\n",
    "        \n",
    "        init_pred = output.max(1, keepdim=True)[1]\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss, here we use negitive log likeleyhood.\n",
    "        \n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Calculate gradients of model.\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Calls an FGSM Attack.\n",
    "        \n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Runs the model on perturbed data.\n",
    "        \n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        # Evaluates proformance.\n",
    "        \n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "        \n",
    "        if final_pred.item() == target.item():\n",
    "            \n",
    "            correct += 1\n",
    "            \n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                \n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            # Save some adv examples for visualization later\n",
    "            \n",
    "            if len(adv_examples) < 5:\n",
    "                \n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # Calculate final accuracy for this epsilon and return it along with the examples.\n",
    "    \n",
    "    return correct/float(len(test_loader)), adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0\n",
      "Test Accuracy - \t Vanila = 0.9561 \t Pertubation = 0.8685 \t AI = 0.813\n",
      "Epsilon: 0.025\n",
      "Test Accuracy - \t Vanila = 0.947 \t Pertubation = 0.8591 \t AI = 0.7969\n",
      "Epsilon: 0.05\n",
      "Test Accuracy - \t Vanila = 0.9312 \t Pertubation = 0.8515 \t AI = 0.7801\n",
      "Epsilon: 0.075\n",
      "Test Accuracy - \t Vanila = 0.9071 \t Pertubation = 0.8408 \t AI = 0.7427\n",
      "Epsilon: 0.1\n",
      "Test Accuracy - \t Vanila = 0.8767 \t Pertubation = 0.8244 \t AI = 0.7113\n",
      "Epsilon: 0.125\n",
      "Test Accuracy - \t Vanila = 0.8387 \t Pertubation = 0.8132 \t AI = 0.6803\n",
      "Epsilon: 0.15\n",
      "Test Accuracy - \t Vanila = 0.7968 \t Pertubation = 0.7946 \t AI = 0.6337\n",
      "Epsilon: 0.175\n",
      "Test Accuracy - \t Vanila = 0.7397 \t Pertubation = 0.7686 \t AI = 0.5996\n",
      "Epsilon: 0.2\n",
      "Test Accuracy - \t Vanila = 0.6835 \t Pertubation = 0.7484 \t AI = 0.5678\n"
     ]
    }
   ],
   "source": [
    "# Runs tests on the three models, user can define what epsilon values they would like to test. \n",
    "# Note: FGSM epsilon value is different to that of the UAA value, smaller values required.\n",
    "\n",
    "accuracies_vani = []\n",
    "examples_vani = []\n",
    "accuracies_pert = []\n",
    "examples_pert = []\n",
    "accuracies_def = []\n",
    "examples_def = []\n",
    "epsilons = [0, .025, .05, .075, .1, .125, .15, .175, .2, .225, .25, .275, .3, .325, .35, .375, .4]\n",
    "\n",
    "# Run test for each epsilon.\n",
    "\n",
    "for eps in epsilons:\n",
    "    acc_vani, ex_vani = test(model_vani, eps, test_loader = test_loader)\n",
    "    accuracies_vani.append(acc_vani)\n",
    "    examples_vani.append(ex_vani)\n",
    "    acc_pert, ex_pert = test(model_pert, eps, test_loader = test_loader)\n",
    "    accuracies_pert.append(acc_pert)\n",
    "    examples_pert.append(ex_pert)\n",
    "    acc_def, ex_def = test(model_def, eps, test_loader = test_loader)\n",
    "    accuracies_def.append(acc_def)\n",
    "    examples_def.append(ex_def)\n",
    "    print(\"Epsilon: {}\\nTest Accuracy - \\t Vanila = {} \\t Pertubation = {} \\t AI = {}\".format(eps, acc_vani, acc_pert, acc_def))\n",
    "\n",
    "# Creates a graph of the three models accuracy against epsilon.\n",
    "    \n",
    "plt.figure(figsize=(5,5))\n",
    "model_vani_line, = plt.plot(epsilons, accuracies_vani, \"*-\")\n",
    "model_pert_line, = plt.plot(epsilons, accuracies_pert, \"*-\")\n",
    "model_def_line, = plt.plot(epsilons, accuracies_def, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .425, step=0.05))\n",
    "plt.title(\"Defense against FGSM\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([model_vani_line, model_pert_line,model_def_line], ['Vanilla Training','Adversarial Trained', 'AI Trained'])\n",
    "plt.savefig('..\\\\figures\\\\User_Defense_against_FGSM.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are used to proform tests of the Universal adversarial attack.\n",
    "# Note: User needs to have ran the loss functions code from the model training section.\n",
    "\n",
    "# Trains a pertubation to maximise its efectiveness against a given model.\n",
    "# Input: The number of epochs, the model to train it on, the pertubation, training data, learning rate and max pertubation size.\n",
    "# Output: A trained pertubation\n",
    "\n",
    "def train_pert(model, pertubation, no_of_epochs = 3, train_loader = train_loader, stepsize = 0.05, epsilon = 3):\n",
    "\n",
    "    # Trains the pertubation for the number of epochs given.\n",
    "    \n",
    "    for epoch in range(no_of_epochs):\n",
    "\n",
    "        for data, target in train_loader:\n",
    "\n",
    "            # Runs the model with the current pertubation.\n",
    "            \n",
    "            output = model(data + pertubation.repeat(train_loader.batch_size, 1, 1, 1))\n",
    "\n",
    "            # Calculates the loss.\n",
    "            \n",
    "            loss = mse_loss_cap(output, target, 3)\n",
    "            \n",
    "            # Gradient decent to improve the pertubation.\n",
    "            \n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            pertubation.data = pertubation.data + stepsize * pertubation.grad\n",
    "            pertubation.data = pertubation.data / torch.norm(pertubation.data.view(-1, 784)) * epsilon\n",
    "    \n",
    "    return pertubation\n",
    "\n",
    "# Tests the proformace of the model given a pertubation.\n",
    "# Input: The model you want to test, the test data, and the pertubation.\n",
    "# Output: Accuracy of the model under this pertubation.\n",
    "\n",
    "def test_pert(model, test_loader, pertubation):\n",
    "\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        # Evaluate the model on the perturbed data.\n",
    "        \n",
    "        output = model(data + pertubation.repeat(test_loader.batch_size, 1, 1, 1))\n",
    "\n",
    "        # Check for success\n",
    "        \n",
    "        final_pred = output.max(1, keepdim=True)[1]\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "\n",
    "    # Calculate final accuracy for this epsilon and return it.\n",
    "    \n",
    "    return correct/float(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs tests on the three models against the universal adversarial attack, user can specify values of epsilon.\n",
    "# Note: User can specify number of epochs for the pertubation to be trained on, though testing indicates no additional proformace\n",
    "# above three epochs.\n",
    "\n",
    "epsilons = [0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6]\n",
    "no_of_epochs = 3\n",
    "\n",
    "pert_epoc_acc_e = []\n",
    "vani_epoc_acc_e = []\n",
    "def_epoc_acc_e = []\n",
    "pertubations = {}\n",
    "\n",
    "# Run test for each epsilon\n",
    "\n",
    "for ep in epsilons:\n",
    "    pertubation_vani_e = Variable(torch.zeros(train_loader.dataset.data.size(1), \\\n",
    "                          train_loader.dataset.data.size(2)), requires_grad=True)\n",
    "    train_pert(model_vani, pertubation_vani_e, no_of_epochs = no_of_epochs, train_loader = train_loader, epsilon = ep)\n",
    "    pertubation_pert_e = Variable(torch.zeros(train_loader.dataset.data.size(1), \\\n",
    "                          train_loader.dataset.data.size(2)), requires_grad=True)\n",
    "    train_pert(model_pert, pertubation_pert_e, no_of_epochs = no_of_epochs, train_loader = train_loader, epsilon = ep)\n",
    "    pertubation_def_e = Variable(torch.zeros(train_loader.dataset.data.size(1), \\\n",
    "                          train_loader.dataset.data.size(2)), requires_grad=True)\n",
    "    train_pert(model_def, pertubation_def_e, no_of_epochs = no_of_epochs, train_loader = train_loader, epsilon = ep)\n",
    "    acc_vani = test_pert(model_vani, test_loader, pertubation_vani_e)\n",
    "    vani_epoc_acc_e.append(acc_vani)\n",
    "    acc_pert = test_pert(model_pert, test_loader, pertubation_pert_e)\n",
    "    pert_epoc_acc_e.append(acc_pert)\n",
    "    acc_def = test_pert(model_def, test_loader, pertubation_def_e)\n",
    "    def_epoc_acc_e.append(acc_def)\n",
    "    pertubations[ep] = [pertubation_vani_e, pertubation_pert_e, pertubation_def_e]\n",
    "    print(\"Epsilon: {} \\nTest Accuracy - \\t Vanila = {} \\t Pertubation = {} \\t AI = {}\".format(ep, acc_vani, acc_pert, acc_def))\n",
    "  \n",
    "# Creates figure of the accuracy of the models against the Uiversal Adverserial Attack against the epsilon values.\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "model_vani_line, = plt.plot(epsilons, vani_epoc_acc_e, \"*-\")\n",
    "model_pert_line, = plt.plot(epsilons, pert_epoc_acc_e, \"*-\")\n",
    "model_def_line, = plt.plot(epsilons, def_epoc_acc_e, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, 6.5, step=1))\n",
    "plt.title(\"Defense against Universal Adverserial Attack\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([model_vani_line, model_pert_line, model_def_line], ['Vanilla Training','Adversarial Trained', 'AI Trained'])\n",
    "plt.savefig('..\\\\Figures\\\\Defense_against_UAA.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# User can view a pertubation generated for a particular model and epsilon value.\n",
    "\n",
    "ep = 2.5\n",
    "\n",
    "# Given the model number, 0 Vanila, 1 Pertubation trained model, and 2 AI trained model.\n",
    "\n",
    "model = 0\n",
    "\n",
    "plt.imshow(pertubations[ep][model].data.numpy())\n",
    "plt.savefig('../Figures/pertubation_vani.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
