\subsection{Preprocessing techniques}

\subsubsection{Image Transformation}
Here we include both bit-depth reduction and total variation minimisation. As shown in the results part, application of bit-depth reduction is less controllable and not as effective as total variation minimisation when we increase the attack level. We should also notice that the fundamental difference between bit-depth reduction and total variation minimisation is that the latter combines randomness to it, which is believed to be a more robust and efficient way to defend against adversarial attacks. Also, the objective function of total variation is complex to be attacked. Hence, for a better defense, we can further combine randomness to our model, and also modify the functions in our model to be as non-differentiable as possible. 

\subsubsection{Defence GAN}
The Defence GAN approach appears promising, despite our inability to replicate recent results.  There are however a number of areas that are yet to be fully explored.  An interesting comparative approach would be to replace the GAN based generator with an autoencoder based model.  This has particular benefits in terms of training as GANs are notoriusly difficult to train and for larger more diverse datasets the easier training method might be more desirable if prediction accuracy doesn't decrease with the blurrier images generated by variational autoencoders.

The other important area to investigate is the nature of the algorithm used to align the generated image with the semantic visual content of the poisoned image.  At present method is to minimise the pixel-wise distance between the generated image and the poisoned image by performing regression on the randomly sampled input vector for the generator.  At classification time this is the method that does most of the heavy lifting and perhaps improving this may improve results or simply speed up classification.  One potential approach if we use an autoencoder is to use the bottleneck layers output to initialise our input vector, potentially using the predicted values as the means for a gaussian we sample from.

\subsubsection{Combining Approaches}
A number of the pre-processing techniques are promising in their own right. Combining the techniques may provide added security.  One such approach could combine pre-processing techniques, such as rescaling with the autoencoder approach, to remove the attack before it is passed to the autoencoder, with the auto-encoder trained to regenerate the un-processed image.  There are a number of possibilities here, some more costly in terms of classification time than others.